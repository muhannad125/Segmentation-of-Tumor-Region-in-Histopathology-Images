{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# wandb is used to track the training process\n","!pip install wandb\n","!wandb login Login_Token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzI8oU2laWHz","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow_datasets as tfds\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import cv2 as cv\n","import os\n","import wandb\n","from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n"]},{"cell_type":"markdown","metadata":{"id":"BfUl59wjqU-f"},"source":["##Preparing and Reading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Start a run, tracking hyperparameters\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"Training U_Net\",\n","\n","    # track hyperparameters and run metadata with wandb.config\n","    config={\n","        \"optimizer\": \"adam\",\n","        \"loss\": \"binary_crossentropy\",\n","        \"metric\": (\"accuracy\", \"MeanIoU\"),\n","        \"epoch\": 5,\n","        \"batch_size\": 32\n","    }\n",")\n","\n","config = wandb.config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ewg5RQ_Npu_t","outputId":"d6d3bafd-59eb-4ae7-ee9d-a56435eabd3b","trusted":true},"outputs":[],"source":["# Path to train database\n","database_path = \"path to database\"\n","database = pd.read_csv(database_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# this code extracts the contents of multiple zip files located in a specified directory\n","# (dir_path) and extracts them into a different directory (new_dir). It iterates over unique\n","# names in a database, assumes the zip files have the same name as the \"name\" column, and \n","# extracts the contents of each zip file into the target directory. {new_dir}\n","#└── {WSI_Name}\n","#    ├── {WSI_Name}_img\n","#    │   └── img_patches\n","#    └── {WSI_Name}_mask\n","#        └── mask_patches\n","#------------------------------------------------------#\n","\n","import zipfile\n","names = database.name.unique()\n","dir_path = \"path of the directory the ziped data\"\n","\n","new_dir = \"path of the directory where the zipped data will be extracted \"\n","for name in names:\n","    zip_file_path = dir_path+ name + '.zip'  # Assuming the zip files have the same name as the \"name\" column\n","\n","    if os.path.exists(zip_file_path):\n","        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","            zip_ref.extractall(new_dir)\n","            print(f\"Successfully extracted {zip_file_path}\")\n","    else:\n","        print(f\"Zip file {zip_file_path} does not exist\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T12:16:22.487024Z","iopub.status.busy":"2023-05-28T12:16:22.486231Z","iopub.status.idle":"2023-05-28T12:16:22.497448Z","shell.execute_reply":"2023-05-28T12:16:22.496469Z","shell.execute_reply.started":"2023-05-28T12:16:22.486982Z"},"id":"f4t5E1YlqLt_","trusted":true},"outputs":[],"source":["# shuffle and split data into training and validation\n","shuffled_data = database.sample(frac=1., random_state=42)\n","train_data, val_data = train_test_split(shuffled_data, test_size=.1, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"7fHUy8NuyDPB"},"source":["## U-Net Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:29.145472Z","iopub.status.busy":"2023-05-26T16:09:29.145040Z","iopub.status.idle":"2023-05-26T16:09:29.154267Z","shell.execute_reply":"2023-05-26T16:09:29.152906Z","shell.execute_reply.started":"2023-05-26T16:09:29.145435Z"},"id":"rNUww3tGyBI4","trusted":true},"outputs":[],"source":["def double_conv_block(x, n_filters):\n","\n","    # Conv2D then ReLU activation\n","    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n","    # Conv2D then ReLU activation\n","    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:29.156359Z","iopub.status.busy":"2023-05-26T16:09:29.155917Z","iopub.status.idle":"2023-05-26T16:09:29.170423Z","shell.execute_reply":"2023-05-26T16:09:29.169186Z","shell.execute_reply.started":"2023-05-26T16:09:29.156324Z"},"id":"WkheU2LkyCrQ","trusted":true},"outputs":[],"source":["def downsample_block(x, n_filters):\n","    f = double_conv_block(x, n_filters)\n","    p = layers.MaxPool2D(2)(f)\n","    p = layers.Dropout(0.3)(p)\n","\n","    return f, p"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:29.173153Z","iopub.status.busy":"2023-05-26T16:09:29.172379Z","iopub.status.idle":"2023-05-26T16:09:29.183478Z","shell.execute_reply":"2023-05-26T16:09:29.182135Z","shell.execute_reply.started":"2023-05-26T16:09:29.173100Z"},"id":"K7PsLh-nyMl9","trusted":true},"outputs":[],"source":["def upsample_block(x, conv_features, n_filters):\n","    # upsample\n","    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n","    # concatenate \n","    x = layers.concatenate([x, conv_features])\n","    # dropout\n","    x = layers.Dropout(0.3)(x)\n","    # Conv2D twice with ReLU activation\n","    x = double_conv_block(x, n_filters)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:29.186073Z","iopub.status.busy":"2023-05-26T16:09:29.185282Z","iopub.status.idle":"2023-05-26T16:09:29.197194Z","shell.execute_reply":"2023-05-26T16:09:29.195911Z","shell.execute_reply.started":"2023-05-26T16:09:29.186021Z"},"id":"hq25YfrIyORh","trusted":true},"outputs":[],"source":["def build_unet_model():\n","\n","    # inputs\n","    inputs = layers.Input(shape=(256,256,3))\n","\n","    # encoder: contracting path - downsample\n","    # 1 - downsample\n","    f1, p1 = downsample_block(inputs, 64)\n","    # 2 - downsample\n","    f2, p2 = downsample_block(p1, 128)\n","    # 3 - downsample\n","    f3, p3 = downsample_block(p2, 256)\n","    # 4 - downsample\n","    f4, p4 = downsample_block(p3, 512)\n","\n","    # 5 - bottleneck\n","    bottleneck = double_conv_block(p4, 1024)\n","\n","    # decoder: expanding path - upsample\n","    # 6 - upsample\n","    u6 = upsample_block(bottleneck, f4, 512)\n","    # 7 - upsample\n","    u7 = upsample_block(u6, f3, 256)\n","    # 8 - upsample\n","    u8 = upsample_block(u7, f2, 128)\n","    # 9 - upsample\n","    u9 = upsample_block(u8, f1, 64)\n","\n","    # outputs\n","    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n","\n","    # unet model with Keras Functional API\n","    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n","\n","    return unet_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mean_iou_manual_tf(y_true, y_pred):\n","    y_pred = tf.round(y_pred)\n","    y_true = tf.reshape(y_true, [-1])\n","    y_pred = tf.reshape(y_pred, [-1])\n","\n","    ious = []\n","    for val in [0, 1]:  # Assuming binary segmentation\n","        y_true_binary = tf.cast(tf.equal(y_true, val), tf.float32)\n","        y_pred_binary = tf.cast(tf.equal(y_pred, val), tf.float32)\n","\n","        intersection = tf.reduce_sum(y_true_binary * y_pred_binary)\n","        union = tf.reduce_sum(y_true_binary) + tf.reduce_sum(y_pred_binary) - intersection\n","        iou = intersection / union\n","        ious.append(iou)\n","    \n","    return tf.reduce_mean(ious)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:44.020068Z","iopub.status.busy":"2023-05-26T16:09:44.019492Z","iopub.status.idle":"2023-05-26T16:09:45.065830Z","shell.execute_reply":"2023-05-26T16:09:45.064787Z","shell.execute_reply.started":"2023-05-26T16:09:44.020023Z"},"id":"YVu65xiHyPzo","trusted":true},"outputs":[],"source":["unet_model = build_unet_model()\n","unet_model.compile(optimizer=config.optimizer, loss=config.loss, metrics=[\"accuracy\", mean_iou_manual_tf])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:45.665305Z","iopub.status.busy":"2023-05-26T16:09:45.664843Z","iopub.status.idle":"2023-05-26T16:09:45.854951Z","shell.execute_reply":"2023-05-26T16:09:45.853519Z","shell.execute_reply.started":"2023-05-26T16:09:45.665264Z"},"id":"p9gspLM0yTvz","outputId":"6215a1d6-88ec-432d-bab9-abac83ab27ec","trusted":true},"outputs":[],"source":["unet_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"qOgzPreJ11NM"},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-26T16:09:48.450765Z","iopub.status.busy":"2023-05-26T16:09:48.450339Z"},"id":"dRn_K903yWCD","outputId":"c6555065-8faa-4bcd-f911-1c16ddc97289","trusted":true},"outputs":[],"source":["# This function loop through all the images and generate batch of images for testing\n","#------------------------------------------------------#\n","\n","dir_path = \"path to the extracted patches\"\n","\n","def train_generator(data, batch_size):\n","    while True:\n","        print(\"entered While\")\n","        data = data.sample(frac=1.)  # Shuffle the data\n","        for start in range(0, len(data), batch_size):\n","            x_batch = []\n","            y_batch = []\n","            end = min(start + batch_size, len(data))\n","            df_batch = data[start:end]\n","            for _, row in df_batch.iterrows():\n","                img = cv.imread(dir_path + row['img_path'])\n","                mask = cv.imread(dir_path + row['mask_path'], cv.IMREAD_GRAYSCALE)\n","                if img is None:\n","                    print(f\"Image not loaded: '{row['image_name']}'\")\n","                    continue\n","                    \n","                if mask is None:\n","                    print(f\"Mask not loaded: {row['mask_name']}\")\n","                    continue                \n","                \n","                img = img / 255.  # Normalize image\n","\n","                x_batch.append(img)\n","                y_batch.append(mask)\n","            yield np.array(x_batch), np.array(y_batch)\n","          \n","\n","# Get generator\n","batch_size = config.batch_size\n","train_gen = train_generator(train_data, batch_size=batch_size)\n","val_gen = train_generator(val_data, batch_size=batch_size)\n","# Set up model checkpoint\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/model_checkpoint.h5', save_best_only=True)\n","\n","\n","val_steps = len(val_data) // batch_size\n","\n","# Train the model\n","history = unet_model.fit(train_gen, validation_data=val_gen, steps_per_epoch=len(train_data) // batch_size ,epochs=config.epoch, validation_steps=val_steps, callbacks=[checkpoint_cb, WandbMetricsLogger(log_freq=5),\n","                      WandbModelCheckpoint(\"models\")])\n","new_history = history.history\n","\n","\n","# Save the final model\n","unet_model.save('model_name.h5')\n","wandb.finish()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
