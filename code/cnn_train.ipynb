{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O3lsC5X1kITD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6FiOHuDAmWeK"
   },
   "outputs": [],
   "source": [
    "class BinaryCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Neural Network (CNN) model for binary classification.\n",
    "\n",
    "    Args:\n",
    "    img_size (int): Size of input images.\n",
    "\n",
    "    Attributes:\n",
    "    features (nn.Sequential): Feature extraction part of the convolutional neural network.\n",
    "    classifier (nn.Sequential): Fully connected classification part.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "            \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.Linear(64 * 32*32, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"        Args:\n",
    "        x (torch.Tensor): Input data tensor.\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of the model.\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rvu-Neh3mYUI"
   },
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class that works with tensors.\n",
    "\n",
    "    Args:\n",
    "    tensors (tuple): A tuple consisting of input data and target data tensors.\n",
    "    transform (callable, optional): A function to apply data transformations.\n",
    "\n",
    "    Attributes:\n",
    "    tensors (tuple): A tuple consisting of input data and target data tensors.\n",
    "    transform (callable): Data transformation function.\n",
    "    size (int): Size of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "        self.size = tensors[1].shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Belirli bir dizindeki veri örneğini getirir.\n",
    "\n",
    "        Args:\n",
    "            index (int): Veri örneğinin dizin değeri.\n",
    "\n",
    "        Returns:\n",
    "            tuple: İlgili veri örneği ve hedef değeri.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the size of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        int: Size of the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sedrjDZ2maO5"
   },
   "outputs": [],
   "source": [
    "def visualize_loss(train_losses,val_losses,val_accuracy):\n",
    "    \"\"\"\n",
    "    A function that visualizes training and validation loss along with validation accuracy.\n",
    "    \n",
    "    Args:\n",
    "    train_losses (list): List of training losses.\n",
    "    val_losses (list): List of validation losses.\n",
    "    val_accuracy (list): List of validation accuracies.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1,figsize=(14,10))\n",
    "    ax[0].plot(range(0, len(train_losses) * 10, 10), train_losses, label='Training Loss')\n",
    "    ax[0].plot(range(0, len(val_losses) * 10, 10), val_losses, label='Validation Loss')\n",
    "    ax[0].set_xlabel('Steps')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].title.set_text('Training and Validation Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(range(0, len(train_losses) * 10, 10), val_accuracy, label='Validation Accuracy')\n",
    "    ax[1].set_xlabel('Steps')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].title.set_text('Validation Accuracy')\n",
    "    plt.savefig('my_plot.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fHqnSLhBm2mU"
   },
   "outputs": [],
   "source": [
    "def read_dataset(paths):\n",
    "    \"\"\"\n",
    "    A function that reads images from given file paths.\n",
    "\n",
    "    Args:\n",
    "    paths (list): List of image file paths.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Tensor of the read images.\n",
    "    \"\"\"\n",
    "        \n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = cv2.imread(path)\n",
    "        images.append(image/255) #scaling\n",
    "    images = np.array(images,dtype=np.float32)\n",
    "    images = np.transpose(images, (0, 3, 1, 2)) # PyTorch library accepts inputs as (channel, height, width)\n",
    "\n",
    "    images = torch.from_numpy(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dIKD7WhpmxTM"
   },
   "outputs": [],
   "source": [
    "def eval_model(val_loader,model,criterion,device):\n",
    "    \"\"\"\n",
    "    A function to evaluate the model.\n",
    "    \n",
    "    Args:\n",
    "    val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
    "    model (torch.nn.Module): Model to be evaluated.\n",
    "    criterion (torch.nn.Module): Loss function.\n",
    "    device (torch.device): Device used (CPU or GPU).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Validation Loss, Accuracy, and F1 score.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  \n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    f1 = 0\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (paths, labels) in enumerate(val_loader):\n",
    "            inputs = read_dataset(paths)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "            val_loss += loss.item() * batch_size\n",
    "            predicted = (outputs >= 0.5).squeeze().long()\n",
    "            if (predicted == labels).sum().item() == 0:\n",
    "                print(predicted,labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            f1 += f1_score(predicted.cpu().to('cpu'),labels,zero_division=1)\n",
    "               \n",
    "    accuracy = 100 * correct / total\n",
    "    f1 = f1 / len(val_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    return val_loss, accuracy,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    \"\"\"\n",
    "    A function that loads the model and optimizer from the specified path.\n",
    "    \n",
    "    Args:\n",
    "    path (str): Path to the file where the model and optimizer are saved.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Loaded model and optimizer.\n",
    "    \"\"\"\n",
    "    model = BinaryCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return model,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3348,
     "status": "ok",
     "timestamp": 1685535404582,
     "user": {
      "displayName": "Emre Arslanoglu",
      "userId": "02840878767035531333"
     },
     "user_tz": -180
    },
    "id": "NvupgsaMkNuf",
    "outputId": "7b6c5afe-37cd-4d41-99d9-6c2b18d8a042",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data shape: 943596 positive label number: 286838, negative label number: 590882\n"
     ]
    }
   ],
   "source": [
    "db_path = 'db.csv'\n",
    "test_files = ['Training_phase_2_046','Training_phase_2_047','Training_phase_2_048','Training_phase_2_049','Training_phase_2_050']\n",
    "\n",
    "db = pd.read_csv(db_path)\n",
    "# Delete the images designated as test files from the database.\n",
    "db = db[~db.name.isin(test_files)]\n",
    "\n",
    "# Seperating positive and negative examples\n",
    "positive_sample = db[db.label == 1]\n",
    "negative_sample = db[db.label == 0]\n",
    "print(f\"all data shape: {db.shape[0]} positive label number: {positive_sample.shape[0]}, negative label number: {negative_sample.shape[0]}\")\n",
    "\n",
    "# Creating a balanced dataset by sampling an equal number of negative and positive examples.\n",
    "db = pd.concat([positive_sample, negative_sample.sample(n = positive_sample.shape[0])], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "img_size = (256,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vXwoxqyhm67S"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BinaryCNN().to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "f1_metric = BinaryF1Score().to(device)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KLHny5JTpLV9"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Taking paths and labels of the images and creating a dataset.\n",
    "X = db['img_path'].values\n",
    "Y = db['label'].values\n",
    "dataset = CustomTensorDataset(tensors=(X, Y))\n",
    "\n",
    "# determining train and validation sizes.\n",
    "train_size = int(0.95* len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "# Train and validation dataloaders are created according to the specified batch size.\n",
    "train_dataset, val_dataset = data.random_split(dataset, [train_size, validation_size])\n",
    "batch_size = 32\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPt67bwRnzEi",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:10.999216832319895, val_loss:10.517222729016307, accuracy:86.25017431320597, f1:0.8713336244342439 \n",
      "train_loss:16.67396251996358, val_loss:14.201749363073139, accuracy:83.10905034165388, f1:0.8107450034703871 \n",
      "train_loss:12.20600115219752, val_loss:11.350242028666978, accuracy:84.15144331334542, f1:0.8178328503989138 \n",
      "train_loss:9.761590174039204, val_loss:7.672654734008687, accuracy:90.81718030958025, f1:0.9045473012319235 \n",
      "train_loss:8.608665653069814, val_loss:8.285102360756236, accuracy:89.46102356714545, f1:0.8903230110560493 \n",
      "train_loss:8.386354035933813, val_loss:6.779514581795653, accuracy:92.0548040719565, f1:0.9170821384411668 \n",
      "train_loss:7.868975687821706, val_loss:8.149372725050851, accuracy:89.82010877144053, f1:0.8949704977328484 \n",
      "train_loss:8.2660282989343, val_loss:6.8209587549551935, accuracy:91.44122158694742, f1:0.9079294086931852 \n",
      "train_loss:7.773365598519643, val_loss:9.434138224675106, accuracy:86.5465067633524, f1:0.8432514709449269 \n",
      "train_loss:7.211937582890193, val_loss:6.13151642005712, accuracy:92.55682610514573, f1:0.9227706909390815 \n",
      "train_loss:7.048106029828389, val_loss:7.761646577612878, accuracy:89.59698786780086, f1:0.8884211022208226 \n",
      "train_loss:7.087654725114504, val_loss:8.246764933717424, accuracy:90.11992748570631, f1:0.8899898816197559 \n",
      "train_loss:6.521855267286301, val_loss:8.321404361538796, accuracy:88.9729465904337, f1:0.8734231148748335 \n",
      "train_loss:6.48350918451945, val_loss:5.629500712107124, accuracy:93.27499651373589, f1:0.932896179953986 \n",
      "train_loss:5.976491939425468, val_loss:5.452060964062328, accuracy:92.92637010179891, f1:0.9240382347289494 \n",
      "train_loss:5.735275503198306, val_loss:4.722147593962043, accuracy:94.3766559754567, f1:0.9417984961652107 \n",
      "train_loss:5.81274923880895, val_loss:6.337598568154551, accuracy:91.63296611351277, f1:0.9082652974882514 \n",
      "train_loss:5.800782433748245, val_loss:7.6553864178716005, accuracy:90.50690280295635, f1:0.9067527842221853 \n",
      "train_loss:5.849123800992966, val_loss:6.389735122388821, accuracy:91.99553758192721, f1:0.911445373565584 \n",
      "train_loss:5.416404751340548, val_loss:5.475256630210175, accuracy:93.39004322967509, f1:0.9342436065913831 \n",
      "train_loss:5.812526637911796, val_loss:4.291374497854856, accuracy:95.11225770464371, f1:0.9484078729592327 \n",
      "train_loss:5.1699292774995165, val_loss:6.614248136048067, accuracy:92.48361455863896, f1:0.9180906847057096 \n",
      "train_loss:5.585104478001594, val_loss:4.463157914620445, accuracy:94.9414307627946, f1:0.9470462148966134 \n",
      "train_loss:4.865776855548223, val_loss:4.4554840499740775, accuracy:94.68344721796123, f1:0.9463467440462168 \n",
      "train_loss:5.295513724088669, val_loss:4.193088340852306, accuracy:95.48528796541626, f1:0.9530538065921632 \n",
      "train_loss:5.326914137204488, val_loss:4.179651751233848, accuracy:95.28308464649282, f1:0.951312815164062 \n",
      "train_loss:4.799810015062491, val_loss:5.498401317176478, accuracy:93.37261190907823, f1:0.9342992036048219 \n",
      "train_loss:5.05245364288489, val_loss:3.723030371111771, accuracy:95.91409845209873, f1:0.9576328642688976 \n",
      "train_loss:4.648756680935621, val_loss:3.7976165711547485, accuracy:95.66308743550411, f1:0.9550674597780359 \n",
      "train_loss:4.6325189463297525, val_loss:3.7760593978524075, accuracy:95.73978524613025, f1:0.9554508636696075 \n",
      "train_loss:4.519723862508933, val_loss:3.8475881407791155, accuracy:95.77464788732394, f1:0.9559753254754253 \n",
      "train_loss:4.652157438447078, val_loss:4.239634990891485, accuracy:95.12620276112118, f1:0.9498609116163585 \n",
      "train_loss:4.654894948204358, val_loss:5.794162279487055, accuracy:93.32031794728769, f1:0.9267930394397685 \n",
      "train_loss:4.395877945919832, val_loss:3.990197298385892, accuracy:95.61427973783294, f1:0.9535007345065851 \n",
      "train_loss:4.093990169763565, val_loss:4.172624405876317, accuracy:95.51666434249059, f1:0.9536059378077038 \n",
      "train_loss:4.162948705752691, val_loss:3.6433474409208118, accuracy:96.04309022451541, f1:0.9586478070122288 \n",
      "train_loss:4.338886301616828, val_loss:4.936907116253107, accuracy:94.54051038906708, f1:0.9418920051111525 \n",
      "train_loss:4.44552184800307, val_loss:5.031672988813724, accuracy:94.28949937247246, f1:0.9425017993610194 \n",
      "train_loss:4.5148954026401045, val_loss:4.3488245809756, accuracy:94.8019801980198, f1:0.9471894175662755 \n",
      "train_loss:4.259172789255778, val_loss:3.518702435486824, accuracy:96.03611769627668, f1:0.9587897925344369 \n",
      "train_loss:4.004086309870084, val_loss:3.780778730560173, accuracy:95.52363687072932, f1:0.9541397828707692 \n",
      "train_loss:4.5565201346079505, val_loss:3.7870165528926827, accuracy:95.97685120624739, f1:0.9574219220515264 \n",
      "train_loss:3.6690815773606302, val_loss:4.459680899878011, accuracy:95.14014781759866, f1:0.9501893663252364 \n",
      "train_loss:4.029199152290821, val_loss:4.6996413265981, accuracy:94.01757077116163, f1:0.9351144727393293 \n",
      "train_loss:4.007449643413226, val_loss:4.9169188628394735, accuracy:93.75261469808953, f1:0.9386193952364258 \n",
      "train_loss:4.195048749446869, val_loss:3.5713727321463287, accuracy:96.23483475108074, f1:0.9602103053281197 \n",
      "train_loss:4.171504900207122, val_loss:3.440605130798309, accuracy:96.23832101520011, f1:0.9606004935738981 \n",
      "train_loss:3.9082786041498183, val_loss:3.100609676561494, accuracy:96.59740621949518, f1:0.9644097583409357 \n",
      "train_loss:3.8382714516917864, val_loss:3.477387380506947, accuracy:96.16859573281272, f1:0.9601392503200402 \n",
      "train_loss:4.133103311558565, val_loss:4.578522011023035, accuracy:94.31390322130805, f1:0.9426575035943131 \n",
      "train_loss:4.008610505064328, val_loss:3.5562162339488, accuracy:96.02565890391855, f1:0.9576818465505154 \n",
      "train_loss:3.7644149242838223, val_loss:3.503675254707618, accuracy:95.9977687909636, f1:0.9577043861158141 \n",
      "train_loss:3.827523877322674, val_loss:3.8150004795446177, accuracy:96.05703528099289, f1:0.95933624280498 \n",
      "train_loss:3.6474871324002742, val_loss:3.306174265467868, accuracy:96.45795565472041, f1:0.9630410954137707 \n",
      "train_loss:4.212267859379451, val_loss:3.47573964369204, accuracy:96.07098033747036, f1:0.9599504954622239 \n",
      "train_loss:3.674831063946088, val_loss:3.2525129420900822, accuracy:96.59391995537582, f1:0.9643387331984968 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 1/5 [3:03:49<12:15:16, 11029.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:3.239495050062736, val_loss:3.211637331523757, accuracy:96.39171663645237, f1:0.9626576692631064 \n",
      "train_loss:3.412564188738664, val_loss:3.1738028385434527, accuracy:96.24180727931949, f1:0.961392768409703 \n",
      "train_loss:3.2715665039916835, val_loss:3.164584036305995, accuracy:96.47190071119788, f1:0.9636212594718425 \n",
      "train_loss:3.5857661642630894, val_loss:3.2858786161993128, accuracy:96.16859573281272, f1:0.9602425755294552 \n",
      "train_loss:2.8651709021627902, val_loss:5.717835865806842, accuracy:94.12564495886208, f1:0.9417459931965144 \n",
      "train_loss:3.280411051760117, val_loss:3.814628752228807, accuracy:95.88620833914378, f1:0.9562044303473363 \n",
      "train_loss:3.5330753080546855, val_loss:3.9523204227072606, accuracy:95.77813415144331, f1:0.9548999132456434 \n",
      "train_loss:3.5303494815031686, val_loss:3.7514809464398304, accuracy:95.78510667968206, f1:0.9572339440289327 \n",
      "train_loss:3.6796632164220013, val_loss:3.214546908768789, accuracy:96.31501882582624, f1:0.960740845446568 \n",
      "train_loss:3.3300991551578045, val_loss:3.0010947848741827, accuracy:96.59740621949518, f1:0.9639990835011784 \n",
      "train_loss:3.1283825880537433, val_loss:4.209573167954533, accuracy:95.15409287407614, f1:0.9515882521994036 \n",
      "train_loss:3.6060471928119657, val_loss:3.9681128551031035, accuracy:95.26913959001534, f1:0.9493802942319622 \n",
      "train_loss:3.45115576411287, val_loss:4.253073417422764, accuracy:95.2621670617766, f1:0.9490645053486779 \n",
      "train_loss:3.456705699165662, val_loss:3.1028524794041643, accuracy:96.55557105006275, f1:0.9640585799787545 \n",
      "train_loss:3.313337437361479, val_loss:3.2397469167858195, accuracy:96.26969739227444, f1:0.9610559782105637 \n",
      "train_loss:3.195641874919335, val_loss:3.8556939494217786, accuracy:95.40161762655138, f1:0.9509345359156045 \n",
      "train_loss:3.218841738651196, val_loss:3.0830211162301344, accuracy:96.7333705201506, f1:0.9661194614310259 \n",
      "train_loss:3.4617515758300823, val_loss:3.2066759791063224, accuracy:96.44749686236229, f1:0.9628514387574251 \n",
      "train_loss:2.868560979490479, val_loss:3.0323590655025163, accuracy:96.6531864454051, f1:0.9651146568938178 \n",
      "train_loss:3.380728124578794, val_loss:3.131543100528095, accuracy:96.65667270952447, f1:0.9645849363089313 \n",
      "train_loss:3.022191223402818, val_loss:2.7896878008492947, accuracy:97.12731836563938, f1:0.9699322403832039 \n",
      "train_loss:3.5444651971757413, val_loss:3.054357578058041, accuracy:96.67410403012133, f1:0.9650601547654519 \n",
      "train_loss:3.391002770960331, val_loss:3.0881518008916276, accuracy:96.76474689722494, f1:0.9666950554555362 \n",
      "train_loss:3.044110582917929, val_loss:3.032098259888963, accuracy:96.51024961651095, f1:0.9631697800048666 \n",
      "train_loss:3.040017656137546, val_loss:3.018945011041369, accuracy:96.88676614140287, f1:0.9675637747455492 \n",
      "train_loss:3.1074966478347776, val_loss:3.166088638762832, accuracy:96.61483754009204, f1:0.964122694497155 \n",
      "train_loss:3.1229346172511576, val_loss:2.611009176093732, accuracy:97.13080462975876, f1:0.9697591592885487 \n",
      "train_loss:2.798958594004313, val_loss:2.771281362161323, accuracy:96.87630734904477, f1:0.9672076823841628 \n",
      "train_loss:3.3514871743321417, val_loss:3.5301052408008404, accuracy:96.39171663645237, f1:0.9620592540408476 \n",
      "train_loss:2.999405693436662, val_loss:2.7995610284300287, accuracy:96.99135406498397, f1:0.968333712478288 \n",
      "train_loss:3.1032596667607626, val_loss:3.633962277352079, accuracy:95.59336215311671, f1:0.9554127158326995 \n",
      "train_loss:3.3738233703871567, val_loss:2.731208738242769, accuracy:96.963463952029, f1:0.9684219943753664 \n",
      "train_loss:2.7223120179524023, val_loss:3.745565137702353, accuracy:95.58987588899735, f1:0.9555824900099329 \n",
      "train_loss:3.07102142855525, val_loss:3.2475157740423115, accuracy:96.49630456003347, f1:0.9629235639979731 \n",
      "train_loss:3.0722435415784517, val_loss:2.8878623890704005, accuracy:96.82052712313485, f1:0.9667033824998961 \n",
      "train_loss:3.107267644306024, val_loss:4.0152345437269945, accuracy:95.01464230930135, f1:0.946107469379227 \n",
      "train_loss:3.370731285015742, val_loss:3.3451342843846734, accuracy:96.33593641054246, f1:0.9614542396634794 \n",
      "train_loss:3.2087850612898667, val_loss:2.8306873370638925, accuracy:97.08199693208758, f1:0.9692812956537055 \n",
      "train_loss:3.076162930528323, val_loss:2.395331452755359, accuracy:97.53521126760563, f1:0.9742169720220961 \n",
      "train_loss:2.880713158448537, val_loss:3.354763709017, accuracy:96.12676056338029, f1:0.9608522250718748 \n",
      "train_loss:2.9951408881445727, val_loss:3.3005177143259323, accuracy:96.43006554176544, f1:0.9621014073000326 \n",
      "train_loss:2.6612984559933346, val_loss:3.1256623742821623, accuracy:96.68107655836006, f1:0.9659861172301086 \n",
      "train_loss:3.0800166361530623, val_loss:2.9185234242458407, accuracy:96.72988425603124, f1:0.9657951889186348 \n",
      "train_loss:2.9578021838267645, val_loss:3.1448400475940312, accuracy:96.61483754009204, f1:0.96418762898891 \n",
      "train_loss:2.8696187865237395, val_loss:2.5284130857507785, accuracy:97.42016455166643, f1:0.9729414058313132 \n",
      "train_loss:3.096534007092317, val_loss:3.9933925887845962, accuracy:95.34932366476085, f1:0.949715513962573 \n",
      "train_loss:2.7996627946197985, val_loss:2.8854857921400994, accuracy:96.97392274438711, f1:0.9686615828811924 \n",
      "train_loss:2.6247013797611, val_loss:2.583375701819907, accuracy:97.25979640217543, f1:0.9715430141259473 \n",
      "train_loss:2.904299692759911, val_loss:2.7076091167154654, accuracy:97.09594198856506, f1:0.9699247465719673 \n",
      "train_loss:2.71731596365571, val_loss:2.713186954641289, accuracy:97.05410681913261, f1:0.9688966171326501 \n",
      "train_loss:2.9514229002098245, val_loss:3.4033556840857004, accuracy:96.19648584576767, f1:0.9595233567488587 \n",
      "train_loss:2.653457600697875, val_loss:3.097217837662136, accuracy:96.64621391716636, f1:0.9647237861150129 \n",
      "train_loss:2.7111130988101166, val_loss:2.8205477698034334, accuracy:97.06107934737136, f1:0.9684913354131506 \n",
      "train_loss:2.8412561652064325, val_loss:2.595072983981109, accuracy:97.28420025101101, f1:0.9713529913745437 \n",
      "train_loss:2.826096903681755, val_loss:2.4579175684596914, accuracy:97.378329382234, f1:0.9722137754152634 \n",
      "train_loss:2.5722074994444846, val_loss:2.904011966550563, accuracy:96.8832798772835, f1:0.9669358092086466 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 2/5 [5:55:37<8:50:14, 10604.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:2.1520681726187467, val_loss:2.3716070130716598, accuracy:97.46548598521824, f1:0.9732162933155493 \n",
      "train_loss:2.1561875702937443, val_loss:2.414634548181641, accuracy:97.45502719286013, f1:0.9731196535769026 \n",
      "train_loss:2.319766070395708, val_loss:2.7220597668709763, accuracy:97.20401617626551, f1:0.9711442661113636 \n",
      "train_loss:2.3857458981623254, val_loss:3.161376449940861, accuracy:96.41612048528796, f1:0.9619315729058624 \n",
      "train_loss:2.4066338406006493, val_loss:2.629157807216995, accuracy:97.21447496862362, f1:0.970609304576997 \n",
      "train_loss:2.2694017195453244, val_loss:2.8865638787763706, accuracy:96.92511504671594, f1:0.9672684321531977 \n",
      "train_loss:2.2698156623045604, val_loss:3.1458992068982843, accuracy:96.74382931250872, f1:0.9655592507462553 \n",
      "train_loss:2.339317378997803, val_loss:2.4983199645028997, accuracy:97.27722772277228, f1:0.9714311991067103 \n",
      "train_loss:2.3588885319481294, val_loss:2.774061905434033, accuracy:97.02273044205829, f1:0.9687814732251757 \n",
      "train_loss:2.384265724917253, val_loss:2.4222252079459072, accuracy:97.4236508157858, f1:0.973180080981346 \n",
      "train_loss:2.2509122231602667, val_loss:2.611623299685011, accuracy:97.36089806163714, f1:0.9722895701831084 \n",
      "train_loss:2.445696927284201, val_loss:2.4382763780744843, accuracy:97.4585134569795, f1:0.9732700515775495 \n",
      "train_loss:2.4470386678973832, val_loss:2.6302161476135653, accuracy:97.09594198856506, f1:0.9699576011402048 \n",
      "train_loss:2.33623632568866, val_loss:2.520800729983028, accuracy:97.39576070283084, f1:0.9727107961249805 \n",
      "train_loss:2.3399509754528602, val_loss:2.5879676004616314, accuracy:97.29117277924976, f1:0.9717353375358915 \n",
      "train_loss:2.1785619955758255, val_loss:2.707365338710306, accuracy:97.1586947427137, f1:0.9703288484824866 \n",
      "train_loss:2.381603636145592, val_loss:2.521150462354306, accuracy:97.38181564635337, f1:0.97281659230353 \n",
      "train_loss:2.410961618050933, val_loss:2.4956685065093516, accuracy:97.36089806163714, f1:0.9722217137507333 \n",
      "train_loss:2.061025282939275, val_loss:2.9639099737008414, accuracy:96.98786780086459, f1:0.9685761276570125 \n",
      "train_loss:2.3669856253514685, val_loss:2.7561144932290516, accuracy:97.12383210152001, f1:0.970559160788098 \n",
      "train_loss:2.109300471742948, val_loss:3.054505099969165, accuracy:96.50676335239157, f1:0.964283551650336 \n",
      "train_loss:2.2453722089901564, val_loss:2.880064614814859, accuracy:96.99135406498397, f1:0.9689414179270138 \n",
      "train_loss:2.389962184925874, val_loss:2.4050168932738445, accuracy:97.48640356993445, f1:0.9737551355624243 \n",
      "train_loss:2.6047619098921615, val_loss:2.650755554337964, accuracy:97.20052991214614, f1:0.9708001816556643 \n",
      "train_loss:2.288315334121386, val_loss:2.2847436639742975, accuracy:97.63979919118673, f1:0.9753248176036876 \n",
      "train_loss:2.272216286386053, val_loss:2.5914802502263483, accuracy:97.27722772277228, f1:0.9713615639084981 \n",
      "train_loss:2.5285610727469128, val_loss:3.0665568240244387, accuracy:96.70896667131503, f1:0.9658759967683797 \n",
      "train_loss:2.4562864208966495, val_loss:2.4204383078327147, accuracy:97.45154092874076, f1:0.9731726538187148 \n",
      "train_loss:2.2755804739892485, val_loss:3.982300339459775, accuracy:96.04309022451541, f1:0.9593313361171215 \n",
      "train_loss:2.266042048384746, val_loss:2.5143049851250954, accuracy:97.40970575930832, f1:0.973032305303078 \n",
      "train_loss:2.4298051586622993, val_loss:2.5860603595175338, accuracy:97.25282387393669, f1:0.9715582189185197 \n",
      "train_loss:2.3008983150621254, val_loss:3.472004642785883, accuracy:96.72639799191187, f1:0.9652554205440441 \n",
      "train_loss:2.4028516892840464, val_loss:2.7185850825530364, accuracy:97.12383210152001, f1:0.9697218296316692 \n",
      "train_loss:2.4129292190074922, val_loss:2.589907886582939, accuracy:97.3086040998466, f1:0.9718020162580989 \n",
      "train_loss:2.2581040747463703, val_loss:3.0336489883337663, accuracy:96.87979361316414, f1:0.9679529441606043 \n",
      "train_loss:2.3416941087941328, val_loss:2.3904316327643635, accuracy:97.38530191047273, f1:0.972784112826388 \n",
      "train_loss:2.191696869805455, val_loss:2.669712636997734, accuracy:97.24236508157858, f1:0.9711980967270111 \n",
      "train_loss:2.175171613134444, val_loss:2.7379490621720204, accuracy:97.23539255333984, f1:0.9712154088857998 \n",
      "train_loss:2.2540367273489634, val_loss:2.546480653618557, accuracy:97.40273323106959, f1:0.9725781403312356 \n",
      "train_loss:2.3724478836605947, val_loss:4.3542953148295265, accuracy:96.16162320457398, f1:0.9590652092239093 \n",
      "train_loss:2.3922311979035538, val_loss:2.810868795001786, accuracy:96.86933482080602, f1:0.9667711152969289 \n",
      "train_loss:2.1236014783134065, val_loss:2.76260025040096, accuracy:97.16915353507181, f1:0.9703173977617203 \n",
      "train_loss:2.4262358932445447, val_loss:2.7485362297648703, accuracy:96.92511504671594, f1:0.9672445656063786 \n",
      "train_loss:2.246282209455967, val_loss:2.3243721307005107, accuracy:97.60145028587365, f1:0.9747867980796558 \n",
      "train_loss:2.40974965184927, val_loss:2.3259229722662247, accuracy:97.63282666294799, f1:0.9750370418166806 \n",
      "train_loss:2.486942996606231, val_loss:2.9857161026801022, accuracy:97.25979640217543, f1:0.9716116890754795 \n",
      "train_loss:2.5071614451209703, val_loss:2.8971119497216398, accuracy:96.9983265932227, f1:0.9684166786752246 \n",
      "train_loss:2.5429104655236006, val_loss:2.4227805800960214, accuracy:97.58750522939619, f1:0.9747038543090133 \n",
      "train_loss:2.3033378793050847, val_loss:2.346535690730996, accuracy:97.73044205829034, f1:0.9761030860219737 \n",
      "train_loss:2.1701097086320322, val_loss:2.5642930551732133, accuracy:97.48640356993445, f1:0.9735669013682097 \n",
      "train_loss:2.1634107163051763, val_loss:2.5196212861716014, accuracy:97.63282666294799, f1:0.9751712558050083 \n",
      "train_loss:2.359841204335292, val_loss:3.0095030079899954, accuracy:97.17612606331056, f1:0.9706366484808849 \n",
      "train_loss:2.0888370700304706, val_loss:2.511857502037865, accuracy:97.42016455166643, f1:0.9727004265376875 \n",
      "train_loss:2.394693213055531, val_loss:2.387790475842214, accuracy:97.5282387393669, f1:0.9741884429630459 \n",
      "train_loss:2.5895618253449597, val_loss:2.2503954296726048, accuracy:97.63282666294799, f1:0.975004961469199 \n",
      "train_loss:2.264031311124563, val_loss:2.168873325646455, accuracy:97.76879096360341, f1:0.9766411513371133 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 3/5 [8:46:33<5:48:11, 10445.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:1.7450651265432437, val_loss:3.3266808277882696, accuracy:96.88676614140287, f1:0.9676545042236853 \n",
      "train_loss:1.5546559400421878, val_loss:2.8423563786922488, accuracy:97.09245572444568, f1:0.9696213787515718 \n",
      "train_loss:1.6034556831419469, val_loss:2.5824629022524905, accuracy:97.50034862641193, f1:0.9738755879694864 \n",
      "train_loss:1.6660728384678563, val_loss:3.1813461503871574, accuracy:96.43355180588482, f1:0.9637217065473168 \n",
      "train_loss:1.8325281751155853, val_loss:2.3149666005294924, accuracy:97.57007390879933, f1:0.9746012544209167 \n",
      "train_loss:1.7183557519999644, val_loss:2.566587003174268, accuracy:97.4236508157858, f1:0.9730874008030357 \n",
      "train_loss:2.130656378803154, val_loss:3.3819833698048107, accuracy:96.62878259656952, f1:0.964806175041971 \n",
      "train_loss:2.625242778112491, val_loss:2.9916036217623994, accuracy:96.78566448194115, f1:0.9664182336771686 \n",
      "train_loss:1.8556884260227282, val_loss:2.7880093719137453, accuracy:97.29117277924976, f1:0.9714749579467599 \n",
      "train_loss:1.712837531765302, val_loss:2.564612151961462, accuracy:97.43759587226329, f1:0.9730304062009573 \n",
      "train_loss:1.8391403486828009, val_loss:2.3582182018669817, accuracy:97.36438432575652, f1:0.9725987363020787 \n",
      "train_loss:1.6955917401239275, val_loss:2.4462243439287046, accuracy:97.53521126760563, f1:0.9741564607235303 \n",
      "train_loss:1.7791722873536249, val_loss:3.7264183933037844, accuracy:96.01171384744109, f1:0.9595473291168317 \n",
      "train_loss:1.989157690666616, val_loss:2.699749295872822, accuracy:97.19007111978803, f1:0.9708750264933341 \n",
      "train_loss:1.649005269507567, val_loss:2.6284002253932126, accuracy:97.72695579417096, f1:0.9764224618247856 \n",
      "train_loss:1.6549673617507021, val_loss:2.62194193270859, accuracy:97.43759587226329, f1:0.97307419448293 \n",
      "train_loss:1.6148741947114467, val_loss:2.696613740296401, accuracy:97.6084228141124, f1:0.9749269001417725 \n",
      "train_loss:1.5185639689924817, val_loss:3.5137545971263204, accuracy:97.29117277924976, f1:0.971996692130452 \n",
      "train_loss:1.8263577319184938, val_loss:2.72314434376864, accuracy:97.3434667410403, f1:0.9721766160998161 \n",
      "train_loss:1.8104843808338047, val_loss:2.922665923231654, accuracy:97.0785106679682, f1:0.96978757859847 \n",
      "train_loss:1.6485131716976562, val_loss:3.1032334368513976, accuracy:97.31557662808534, f1:0.971840104174684 \n",
      "train_loss:2.0195158222690224, val_loss:2.6149514428980507, accuracy:97.2737414586529, f1:0.9715174998592323 \n",
      "train_loss:1.7356037400787074, val_loss:2.617331473217029, accuracy:97.39227443871148, f1:0.9725796708076463 \n",
      "train_loss:1.8001991075774033, val_loss:2.5909358729237697, accuracy:97.6084228141124, f1:0.9747076159191624 \n",
      "train_loss:1.7653409608453512, val_loss:2.939007622886495, accuracy:97.12731836563938, f1:0.9700352137849373 \n",
      "train_loss:1.8687791124731303, val_loss:3.0528479201247793, accuracy:96.98438153674522, f1:0.9688347169207465 \n",
      "train_loss:1.8141161539405584, val_loss:2.4917103095497177, accuracy:97.37135685399525, f1:0.9722377210334345 \n",
      "train_loss:2.023665352463722, val_loss:2.869187715069838, accuracy:97.07502440384883, f1:0.9689564947838938 \n",
      "train_loss:1.5256508258295556, val_loss:3.7112257539366302, accuracy:96.7682331613443, f1:0.9656508330195133 \n",
      "train_loss:1.8737453976646066, val_loss:2.844520512457476, accuracy:97.57007390879933, f1:0.9742522960394854 \n",
      "train_loss:1.9123854989372193, val_loss:2.477593121830054, accuracy:97.68163436061916, f1:0.9756750676808794 \n",
      "train_loss:1.4445549843460321, val_loss:3.1888527332274546, accuracy:96.78915074606053, f1:0.9669846392460458 \n",
      "train_loss:1.7199396247665086, val_loss:2.7428115041990875, accuracy:97.42016455166643, f1:0.9726972231677388 \n",
      "train_loss:1.7020235546429952, val_loss:2.65520482022552, accuracy:97.57007390879933, f1:0.9744026034798225 \n",
      "train_loss:1.7764929700363428, val_loss:2.7930022654193167, accuracy:97.15520847859433, f1:0.970289167204184 \n",
      "train_loss:1.9365305010601879, val_loss:3.3128992956102628, accuracy:97.17612606331056, f1:0.9708879417303965 \n",
      "train_loss:1.7170659273614486, val_loss:3.353847993877296, accuracy:97.24236508157858, f1:0.9712913853120366 \n",
      "train_loss:2.2001681473851202, val_loss:2.5317767705631296, accuracy:97.65025798354483, f1:0.9754854724165472 \n",
      "train_loss:1.8082750901207327, val_loss:2.527216584121636, accuracy:97.61539534235114, f1:0.9748947361211254 \n",
      "train_loss:1.8765047072526067, val_loss:2.539555890653843, accuracy:97.5735601729187, f1:0.9747542460682023 \n",
      "train_loss:1.6359989444538952, val_loss:2.642856134103825, accuracy:97.42713707990518, f1:0.9733482216712501 \n",
      "train_loss:1.7774012758163735, val_loss:2.9325766957997277, accuracy:97.0680518756101, f1:0.9692990712699916 \n",
      "train_loss:1.863342946295937, val_loss:2.8362111669893446, accuracy:96.97392274438711, f1:0.968130178732688 \n",
      "train_loss:1.8372761532912651, val_loss:2.750442292008636, accuracy:97.47594477757634, f1:0.9737367129217347 \n",
      "train_loss:1.7385466804603735, val_loss:2.7509446082929503, accuracy:97.47943104169572, f1:0.9736023300454019 \n",
      "train_loss:1.694394864446173, val_loss:2.8137323900043896, accuracy:97.46548598521824, f1:0.9736960075374047 \n",
      "train_loss:1.6699635886587203, val_loss:2.529078746812549, accuracy:97.57007390879933, f1:0.9744750619005446 \n",
      "train_loss:1.7303117998689412, val_loss:2.8779564534200808, accuracy:97.11685957328127, f1:0.970294281803959 \n",
      "train_loss:1.6862835445565483, val_loss:3.2434314505976842, accuracy:97.09594198856506, f1:0.9697167910392004 \n",
      "train_loss:2.0684723497057953, val_loss:2.554745431626039, accuracy:97.5631013805606, f1:0.9742588428036729 \n",
      "train_loss:1.7284327274250488, val_loss:2.514873897175044, accuracy:97.55612885232185, f1:0.9743419847096122 \n",
      "train_loss:1.7493863800913096, val_loss:4.792970400656612, accuracy:94.62069446381258, f1:0.9414120845353869 \n",
      "train_loss:1.6986441083500783, val_loss:2.662281019806264, accuracy:97.35392553339841, f1:0.9720102408722072 \n",
      "train_loss:1.795665549747646, val_loss:2.496492440132227, accuracy:97.61888160647051, f1:0.9748124551487776 \n",
      "train_loss:1.7065362730870643, val_loss:2.877610352721975, accuracy:97.61539534235114, f1:0.9749863312201047 \n",
      "train_loss:1.9883965581531327, val_loss:2.598475658823814, accuracy:97.15172221447497, f1:0.9703625914212758 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 4/5 [11:49:17<2:57:30, 10650.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:1.3873573241072397, val_loss:3.086884297704617, accuracy:96.91116999023846, f1:0.9675983396511486 \n",
      "train_loss:1.181206127529343, val_loss:3.5881048840057383, accuracy:96.97740900850648, f1:0.9686939146417789 \n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "for epoch in tqdm(range(5)):\n",
    "  running_loss = 0.0\n",
    "\n",
    "  for batch_idx, (paths, labels) in enumerate(train_loader):\n",
    "    inputs = read_dataset(paths)\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "      \n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Loss is calculated for each batch and accumulated cumulatively as we progress.\n",
    "    running_loss += loss.item() * batch_size\n",
    "    \n",
    "    \n",
    "    if batch_idx % 300 == 299:\n",
    "        model.eval()    \n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        f1 = 0\n",
    "        running_loss = running_loss / 300\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (paths, labels) in enumerate(val_loader):\n",
    "                inputs = read_dataset(paths)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "                val_loss += loss.item() * batch_size\n",
    "                predicted = (outputs >= 0.5).squeeze().long()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                f1 += f1_score(labels.cpu(),predicted.to('cpu'),zero_division=1)\n",
    "                   \n",
    "        accuracy = 100 * correct / total\n",
    "        f1 = f1 / len(val_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        train_losses.append(running_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"train_loss:{running_loss}, val_loss:{val_loss}, accuracy:{accuracy}, f1:{f1} \")\n",
    "        val_accuracy.append(accuracy)\n",
    "        running_loss= 0\n",
    "\n",
    "  # The model and optimizer are saved at each epoch based on the timestamp when they are recorded.\n",
    "  checkpoint = {\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict()\n",
    "  }\n",
    "  now = datetime.now()\n",
    "  current_time = now.strftime(\"_%H_%M\")\n",
    "  MODEL_PATH = f\"model/model_checkpoint{current_time}.pth\"\n",
    "  torch.save(checkpoint, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_loss(train_losses,val_losses,val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIxUBWG8ewP6D1092eNpvE",
   "mount_file_id": "1TF-n76gCFvXHJMloqiCQ6FNJBA1oyETe",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
