{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import utils\nimport cv2 as cv\nimport os\nimport numpy as np\nfrom sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score","metadata":{"id":"mygZ66p1H1oJ","execution":{"iopub.status.busy":"2023-06-14T09:02:54.169385Z","iopub.execute_input":"2023-06-14T09:02:54.169829Z","iopub.status.idle":"2023-06-14T09:03:04.590824Z","shell.execute_reply.started":"2023-06-14T09:02:54.169796Z","shell.execute_reply":"2023-06-14T09:03:04.589652Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Path to test database\ndatabase_path = \"path to database\"\ndatabase = pd.read_csv(database_path)","metadata":{"id":"41eYLOWtDvlM","execution":{"iopub.status.busy":"2023-06-14T09:03:04.593362Z","iopub.execute_input":"2023-06-14T09:03:04.594191Z","iopub.status.idle":"2023-06-14T09:03:05.618615Z","shell.execute_reply.started":"2023-06-14T09:03:04.594153Z","shell.execute_reply":"2023-06-14T09:03:05.617531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# this code extracts the contents of multiple zip files located in a specified directory\n# (dir_path) and extracts them into a different directory (new_dir). It iterates over unique\n# names in a database, assumes the zip files have the same name as the \"name\" column, and \n# extracts the contents of each zip file into the target directory. {new_dir}\n#└── {WSI_Name}\n#    ├── {WSI_Name}_img\n#    │   └── img_patches\n#    └── {WSI_Name}_mask\n#        └── mask_patches\n#------------------------------------------------------#\n\nimport zipfile\nnames = database.name.unique()\ndir_path = \"path of the directory the ziped data\"\n\nnew_dir = \"path of the directory where the zipped data will be extracted \"\nfor name in names:\n    zip_file_path = dir_path+ name + '.zip'  # Assuming the zip files have the same name as the \"name\" column\n\n    if os.path.exists(zip_file_path):\n        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n            zip_ref.extractall(new_dir)\n            print(f\"Successfully extracted {zip_file_path}\")\n    else:\n        print(f\"Zip file {zip_file_path} does not exist\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wz-9zRDHDpzD","outputId":"b92763f1-4add-4012-c2d0-7b0f490c59fb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function is used to calculate mean IoU scores inside the model.\n# It is important to define this function in order to be able to load the model\n#------------------------------------------------------#\ndef mean_iou_manual_tf(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    y_true = tf.reshape(y_true, [-1])\n    y_pred = tf.reshape(y_pred, [-1])\n\n    ious = []\n    for val in [0, 1]:  # Assuming binary segmentation\n        y_true_binary = tf.cast(tf.equal(y_true, val), tf.float32)\n        y_pred_binary = tf.cast(tf.equal(y_pred, val), tf.float32)\n\n        intersection = tf.reduce_sum(y_true_binary * y_pred_binary)\n        union = tf.reduce_sum(y_true_binary) + tf.reduce_sum(y_pred_binary) - intersection\n        iou = intersection / union\n        ious.append(iou)\n\n    return tf.reduce_mean(ious)\n\nutils.get_custom_objects()['mean_iou_manual_tf'] = mean_iou_manual_tf","metadata":{"id":"hPMTu4tFMx6Y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet_model = tf.keras.models.load_model(\"path to the model\")\n","metadata":{"id":"PpzIbJYVIR1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function loop through all the images and generate batch of images for testing\n#------------------------------------------------------#\ndir_path = \"path to the extracted patches\"\n\ndef test_generator(data, batch_size):\n\n        print(\"entered While\")\n\n        for start in range(0, len(data), batch_size):\n            x_batch = []\n            y_batch = []\n            end = min(start + batch_size, len(data))\n            df_batch = data[start:end]\n            for _, row in df_batch.iterrows():\n                img = cv.imread(dir_path + row['img_path'])\n                mask = cv.imread(dir_path + row['mask_path'], cv.IMREAD_GRAYSCALE)\n                if img is None:\n                    print(f\"Image not loaded: '{row['image_name']}'\")\n                    continue\n\n                if mask is None:\n                    print(f\"Mask not loaded: {row['mask_name']}\")\n                    continue\n\n                img = img / 255.  # Normalize image\n\n                x_batch.append(img)\n                y_batch.append(mask)\n            yield np.array(x_batch), np.array(y_batch)","metadata":{"id":"Uq5NoOvYNFsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cancered = database[database.label == 1]\npartially_cancered = database[database.label == -1]\nbenign = database[database.label == 0]","metadata":{"id":"MXZqDNCxSpTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The model is tested through all test data and the final results are printed\nbatch_size = 16\nthreshold = 0.5\ntest_gen = test_generator(cancered, batch_size)\n# Iterate over the evaluation batches\noverall_mean_iou = 0\noverall_mean_f1 = 0\noverall_mean_recall = 0\noverall_mean_precision = 0\noverall_mean_accuracy = 0\ntotal_batches = 0\n\nfor images, masks in test_gen:\n    # Perform inference with your model\n    predictions = unet_model.predict(images)\n    predictions = (predictions > threshold).astype(np.float32)\n\n    masks = masks.flatten()\n    predictions = predictions.flatten()\n\n    # Calculate metrics for the batch\n    batch_iou = mean_iou_manual_tf(masks, predictions)\n    batch_f1 = f1_score(masks, predictions, zero_division = 1)\n    batch_recall = recall_score(masks, predictions, zero_division = 1)\n    batch_precision = precision_score(masks, predictions, zero_division = 1)\n    batch_accuracy = accuracy_score(masks, predictions)\n\n    # Accumulate batch results\n    overall_mean_iou += batch_iou\n    overall_mean_f1 += batch_f1\n    overall_mean_recall += batch_recall\n    overall_mean_precision += batch_precision\n    overall_mean_accuracy += batch_accuracy\n    total_batches += 1\n\n    # Print batch results\n    print(\"Batch\", total_batches)\n    print(\"Mean IoU:\", batch_iou)\n    print(\"Accuracy:\", batch_accuracy)\n    print(\"F1 Score:\", batch_f1)\n    print(\"Recall:\", batch_recall)\n    print(\"Precision:\", batch_precision)\n\n# Calculate overall means\noverall_mean_iou /= total_batches\noverall_mean_f1 /= total_batches\noverall_mean_recall /= total_batches\noverall_mean_precision /= total_batches\noverall_mean_accuracy /= total_batches\n\n# Print the results\nprint(\"Cancered\")\nprint(\"Overall Mean IoU:\", overall_mean_iou)\nprint(\"Overall Mean F1 Score:\", overall_mean_f1)\nprint(\"Overall Mean Recall:\", overall_mean_recall)\nprint(\"Overall Mean Precision:\", overall_mean_precision)\nprint(\"Overall Mean Accuracy:\", overall_mean_accuracy)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpsEzV0lNc1z","outputId":"3a5de7eb-a6ac-49e9-d9d6-28237be00986"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shows examples of the prediction\n#----------------------------------------------------------------------#\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nbatch_size = 32\ntest_gen = test_generator(val_data, batch_size)\n\n# Get a batch of data\nimages, masks = next(test_gen)\nthreshold = 0.5\n# Get predictions for this batch\npredictions = unet_model_3.predict(images)\npredictions = (predictions > threshold).astype(np.float32)\nfig, axes = plt.subplots(batch_size, 3, figsize=(20, 10 * batch_size))\n\nfor idx in range(batch_size):\n    # Show original image\n    axes[idx, 0].imshow(images[idx])\n    axes[idx, 0].set_title('Original Image')\n\n    # Show ground truth mask\n    axes[idx, 1].imshow(masks[idx], cmap='gray')\n    axes[idx, 1].set_title('Ground Truth Mask')\n\n    # Show predicted mask\n\n    axes[idx, 2].imshow(predictions[idx], cmap='gray')\n    axes[idx, 2].set_title('Predicted Mask')\n\nplt.tight_layout()\nplt.show()\n\n","metadata":{"colab":{"background_save":true},"id":"yx7WIkLxJy7L","outputId":"b582aafd-550d-4e72-80ee-4ec7b49e6b87"},"execution_count":null,"outputs":[]}]}